<div align="center">

# ğŸ“ Call Center QA Platform

### AI-Powered Call Quality Evaluation & Analytics

[![React](https://img.shields.io/badge/React-19.0-61DAFB?logo=react&logoColor=white)](https://react.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-3178C6?logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Vite](https://img.shields.io/badge/Vite-6.4-646CFF?logo=vite&logoColor=white)](https://vitejs.dev/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-4.1-38B2AC?logo=tailwind-css&logoColor=white)](https://tailwindcss.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)

**A modern, full-featured platform for automating call center quality assurance using Azure AI services.**

[Features](#-key-features) â€¢ [Quick Start](#-quick-start) â€¢ [Configuration](#%EF%B8%8F-configuration) â€¢ [Usage](#-usage-guide) â€¢ [Architecture](#-project-architecture)

</div>

---

## ğŸ¯ Overview

The Call Center QA Platform is a comprehensive React-based dashboard that streamlines the quality assurance process for call centers. It leverages **Azure Speech Services** for accurate transcription and **Azure OpenAI** for intelligent evaluation against customizable quality criteria.

### What It Does

- ğŸ“¤ **Upload & Import**: Import call metadata from Excel/CSV with drag-and-drop audio file upload
- ğŸ¤ **Transcription**: Convert audio recordings to text using Azure Speech-to-Text with 150+ language support
- ğŸ¤– **AI Evaluation**: Automatically score calls against customizable quality criteria using Azure OpenAI
- ğŸ“Š **Analytics**: Visualize performance trends, agent comparisons, and criteria insights
- ğŸ¨ **Personalization**: Customize branding, themes, and schemas per use case

---

## âœ¨ Key Features

### Core Functionality

| Feature | Description |
|---------|-------------|
| **Multi-Language Transcription** | Support for 150+ languages with automatic language detection |
| **Customizable Evaluation Rules** | Create and modify evaluation criteria with flexible scoring |
| **Dynamic Schema System** | Define custom data schemas for different call types |
| **Real-time Analytics** | Interactive charts and dashboards for performance insights |
| **Agent Performance Tracking** | Individual agent scorecards and trend analysis |
| **Batch Operations** | Process multiple calls simultaneously |

### Advanced Features

- **ğŸ”§ Schema Discovery Wizard**: AI-assisted schema creation from sample data
- **ğŸ“‹ Evaluation Rules Generator**: Automatically generate evaluation rules based on business context
- **ğŸ¯ Topic Taxonomy**: Hierarchical topic classification for calls
- **ğŸ’¡ Custom Insight Categories**: Define business-specific AI insights
- **ğŸ¨ White-Label Support**: Custom logos, titles, and color themes
- **ğŸ”„ Data Migration**: Automatic schema versioning and migration

---

## ğŸ› ï¸ Technology Stack

| Category | Technologies |
|----------|--------------|
| **Frontend** | React 19, TypeScript 5.7, Vite 6.4 |
| **Styling** | Tailwind CSS 4.1, Radix UI Components |
| **State Management** | React Hooks, Local Storage |
| **Charts & Visualization** | Recharts, D3.js |
| **AI Services** | Azure Speech-to-Text, Azure OpenAI |
| **Data Handling** | xlsx, date-fns, Zod validation |
| **UI Components** | shadcn/ui, Lucide Icons, Phosphor Icons |

---

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:

- **Node.js** 18.x or higher
- **npm** 9.x or higher
- **Azure Subscription** with the following services:
  - Azure Speech Services (for transcription)
  - Azure OpenAI Service (for evaluation)

---

## ğŸš€ Quick Start

### 1. Clone and Install

```bash
# Clone the repository
git clone https://github.com/amantaras/call-center-performance.git
cd call-center-performance

# Install dependencies
npm install
```

### 2. Start Development Server

```bash
npm run dev
```

Visit the dev server URL printed in the terminal (typically `http://localhost:5173`).

### 3. Configure Azure Services

1. Click **"Azure Services"** button in the top-right corner
2. Enter your Azure Speech and OpenAI credentials (see [Configuration](#%EF%B8%8F-configuration) below)
3. Click **"Save Configuration"**

### 4. Import Your First Call

1. Click **"Import CSV"** to import call metadata
2. Upload or link audio files
3. Click **"Transcribe"** to generate transcripts
4. Click **"Evaluate"** to run AI quality assessment

---

## âš™ï¸ Configuration

### Azure Services Configuration

Access the configuration dialog by clicking **"Azure Services"** in the application header.

#### Azure Speech Service

| Setting | Description | Example |
|---------|-------------|---------|
| **Region** | Your Azure Speech resource region | `eastus`, `westus2`, `westeurope` |
| **Subscription Key** | Speech service subscription key | `abc123...` |
| **API Version** | Speech-to-Text API version | `2025-10-15` (recommended) |
| **Languages** | Languages for auto-detection | Select from 150+ options |
| **Diarization** | Enable speaker separation | Toggle on/off |
| **Min/Max Speakers** | Expected speaker count range | 1-10 |

#### Azure OpenAI Service

| Setting | Description | Example |
|---------|-------------|---------|
| **Endpoint URL** | Your Azure OpenAI endpoint | `https://your-resource.openai.azure.com/` |
| **API Key** | OpenAI service API key | `xyz789...` |
| **Deployment Name** | Your GPT model deployment | `gpt-4`, `gpt-4o` |
| **API Version** | Azure OpenAI API version | `2024-12-01-preview` |
| **Reasoning Effort** | Token budget for reasoning | `minimal`, `low`, `medium`, `high` |

#### Text-to-Speech (Optional)

| Setting | Description |
|---------|-------------|
| **Enabled** | Toggle TTS functionality |
| **Default Voices** | Configure male/female voice options |
| **Output Format** | Audio quality: 16kHz, 24kHz, or 48kHz MP3 |

### Configuration Persistence

Settings are stored in two locations for reliability:
- **localStorage**: Primary storage (`azure-services-config` key)
- **Cookie backup**: Base64-encoded backup (`ccp_azure_config`) for session recovery

---

## ğŸ“– Usage Guide

### Step 1: Schema Setup

Before importing calls, select or create a schema that matches your data structure.

1. **Select Schema**: Use the schema dropdown in the header
2. **Create New Schema**: 
   - Click "Manage Schemas"
   - Use the Schema Discovery Wizard for AI-assisted creation
   - Or manually define fields

### Step 2: Import Call Data

#### From CSV/Excel

1. Click **"Import CSV"** button
2. Choose your file or paste data directly
3. Map columns to schema fields
4. Set the audio folder path:
   - `/audio` if files are in `public/audio`
   - `http://localhost:8080` for external server

#### Direct Upload

1. Click **"Upload Calls"**
2. Drag and drop audio files
3. Enter metadata manually or use auto-detection

> **Note**: Audio files must be served over HTTP. Browsers cannot fetch local `file://` URLs.

### Step 3: Transcription

1. Select calls with **"Uploaded"** status
2. Click **"Transcribe Selected"** or use the ğŸ¤ icon
3. Wait for Azure Speech processing (30 seconds to 5 minutes per file)
4. Status changes to **"Transcribed"** when complete

### Step 4: Evaluation

1. Select calls with **"Transcribed"** status
2. Click **"Evaluate Selected"** or use the ğŸ§ª icon
3. AI evaluates against your configured criteria
4. Review scores and detailed feedback

### Step 5: Analytics

Navigate to the **Analytics** tab to view:
- Overall performance trends
- Criteria pass rates
- Score distributions
- Topic analysis

Navigate to the **Agents** tab for:
- Individual agent performance
- Comparative analysis
- Strengths and improvement areas

---

## ğŸ“ Project Architecture

```
call-center-performance/
â”œâ”€â”€ public/
â”‚   â””â”€â”€ audio/              # HTTP-served audio files
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ ui/             # Reusable UI components (shadcn/ui)
â”‚   â”‚   â”œâ”€â”€ views/          # Main view components
â”‚   â”‚   â”œâ”€â”€ analytics/      # Analytics-specific components
â”‚   â”‚   â””â”€â”€ call-player/    # Audio player components
â”‚   â”œâ”€â”€ hooks/              # Custom React hooks
â”‚   â”œâ”€â”€ lib/                # Utility functions
â”‚   â”‚   â”œâ”€â”€ analytics.ts    # Analytics calculations
â”‚   â”‚   â”œâ”€â”€ csv-parser.ts   # Excel/CSV processing
â”‚   â”‚   â”œâ”€â”€ evaluation-criteria.ts  # Default evaluation rules
â”‚   â”‚   â”œâ”€â”€ personalization.ts      # Theme customization
â”‚   â”‚   â””â”€â”€ speech-languages.ts     # Language definitions
â”‚   â”œâ”€â”€ prompts/            # AI prompt templates
â”‚   â”œâ”€â”€ services/           # Business logic services
â”‚   â”‚   â”œâ”€â”€ azure-openai.ts # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ transcription.ts# Speech-to-Text integration
â”‚   â”‚   â”œâ”€â”€ schema-manager.ts# Schema management
â”‚   â”‚   â””â”€â”€ rules-generator.ts# Evaluation rules engine
â”‚   â”œâ”€â”€ styles/             # CSS styles
â”‚   â””â”€â”€ types/              # TypeScript type definitions
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ tsconfig.json
```

### Key Components

| Component | Purpose |
|-----------|---------|
| `CallsView` | Main calls table with actions |
| `CallDetailDialog` | Individual call details and transcript |
| `ConfigDialog` | Azure services configuration |
| `RulesEditorDialog` | Evaluation rules management |
| `SchemaDiscoveryWizard` | AI-assisted schema creation |
| `AnalyticsView` | Performance dashboards |
| `AgentsView` | Agent performance tracking |

---

## ğŸ”§ Available Scripts

| Command | Description |
|---------|-------------|
| `npm run dev` | Start development server |
| `npm run build` | Build for production |
| `npm run preview` | Preview production build |
| `npm run lint` | Run ESLint |

---

## ğŸ“Š Status Flow

Calls progress through the following statuses:

```
Uploaded â†’ Transcribing â†’ Transcribed â†’ Evaluated
                              â†“
                           Failed (on error)
```

| Status | Badge Color | Description |
|--------|-------------|-------------|
| **Uploaded** | ğŸŸ¦ Blue | Call data uploaded, ready for transcription |
| **Transcribing** | ğŸŸ¨ Yellow | Audio being processed by Azure Speech |
| **Transcribed** | ğŸŸ© Green | Transcript ready for evaluation |
| **Evaluated** | ğŸŸ¢ Dark Green | Complete with scores |
| **Failed** | ğŸ”´ Red | Error occurred (check details) |

---

## ğŸ”’ Security

- API credentials are stored in browser localStorage (never sent to external servers except Azure)
- Audio files are fetched directly from configured sources
- All processing happens client-side or via Azure services
- See [SECURITY.md](./SECURITY.md) for vulnerability reporting

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.

---

## ğŸ“š Additional Resources

- [Transcription Guide](./TRANSCRIPTION-GUIDE.md) - Detailed transcription workflow
- [Language Selector Feature](./LANGUAGE_SELECTOR_FEATURE.md) - Multi-language support documentation
- [Schema Audio Folders](./SCHEMA_AUDIO_FOLDERS.md) - Schema-specific audio organization
- [Implementation Summary](./IMPLEMENTATION_SUMMARY.md) - Dynamic evaluation rules

---

<div align="center">

**Built with â¤ï¸ using React, TypeScript, and Azure AI**

</div>
